# EmotionPred
Предсказание смайликов на основе фрагмента текста
## Задача - выдача подсказки в виде смайла на основе введенного текста - задача классификации.

### Источники данных
[Go Emotions](https://github.com/google-research/google-research/tree/master/goemotions/) – датасет из 58 000 комментариев пользователей Reddit. Содержит 27 видов смайлов и также нейтральные (без смайлов) комментарии. Максимальная длина твита составляет 26 символов.

### Анализ данных
В процессе анализа датасета были выявлены следующие проблемы:
1)	Количество комментариев со смайлами и без смайлов сильно не сбалансированы
2)	Некоторым комментариям соответствуют сразу несколько смайлов

Для решения **проблемы №1** была попытка убрать комментарии без смайлов из обучения и сократить количество комментариев без смайлов (12 800) до количества самого наибольшего количества комментариев со смайлами (2 800). Однако при этом происходит сильное уменьшение объема выборки. Так, сокращение количества комментариев без смайлов на 10 000 приводит к потере 25% объема выборки. Поэтому данная задача была решена выбором метрики f1-score вместо accuracy.
![image](https://github.com/lili-alsh/EmotionPred/assets/54451801/4c48159a-b12e-4934-a511-3ea7f23cf3b9)
При этом следует отметить, что размеченные нейтрально комментарии действительно не несут в себе эмоциональной окраски. Поэтому удалять их из данных означало бы потерять часть содержательного смысла.

**Проблема №2** была решена следующим образом. В комментариях, где указано сразу несколько смайлов, был оставлен тот смайл, который представлен в общем объеме выборки в наименьшем количестве.

Также для решения задачи необходимо было предварительно обработать текст. Были применены следующие способы очистки текста:
1)	Удалена пунктуация
2)	Удалены стоп-слова
3)	В тексте оставлены только буквы a-z
4)	Удалены лишние пробелы, т.к. комментарии написаны пользователями, могут быть ошибки
5)	Удалены одни и те же символы, повторяющиеся друг за другом более 2 раз
6)	Удалены одиночные символы
7)	Слова приведены к нижнему регистру

### Метрики
f1-score, т.к. обучающая выборка несбалансирована

###  Используемые методы
1. Random Forest с TF-IDF векторизацией. 
2. FastText
3. LSTM
  Была построена модель следующей архитектуры
![image](https://github.com/lili-alsh/EmotionPred/assets/54451801/38b00b75-501c-44ed-b7c5-27bfda512c66)

5. BERT
   Использована модель ["cointegrated/rubert-tiny"](https://habr.com/ru/articles/692570/). cointegrated/rubert-tiny предназначена в первую очередь для классификации коротких текстов. Это англо-русский BERT размером 45MB/ обученный способом дистилляции (способ перекладывания знаний из одной модели в другую)

### Вывод
Наилучший результат по метрике f1-score 0,56 был получен с помощью модели RandomForest. Причина - короткая длина текста твита. Также следует учесть, что твиты пишутся с ошибками, сокращениями и сленгом. Несмотря на то, что была проведена предварительная обработка текста, от всех неточностей и ошибок избавиться невозможно.
